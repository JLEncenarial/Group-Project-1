{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How I plan to start this off. (Jean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just took whatever libraries he put on from class notes so I don't go back and forth. Will change later (maybe?)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "train_df = pd.read_csv(\"train.csv.zip\")\n",
    "train_df = train_df.head(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: (1000,)\n",
      "vectorized: (1000, 150)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>after</th>\n",
       "      <th>again</th>\n",
       "      <th>all</th>\n",
       "      <th>also</th>\n",
       "      <th>am</th>\n",
       "      <th>an</th>\n",
       "      <th>and</th>\n",
       "      <th>any</th>\n",
       "      <th>are</th>\n",
       "      <th>...</th>\n",
       "      <th>which</th>\n",
       "      <th>who</th>\n",
       "      <th>why</th>\n",
       "      <th>wikipedia</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>would</th>\n",
       "      <th>wp</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     about  after  again  all  also  am  an  and  any  are  ...  which  who  \\\n",
       "585      0      0      0    0     0   0   0    2    0    1  ...      0    0   \n",
       "203      1      0      0    0     0   1   0    2    0    1  ...      0    0   \n",
       "573      1      0      0    1     1   0   0    1    0    2  ...      0    0   \n",
       "394      0      0      0    0     0   0   0    3    1    0  ...      1    0   \n",
       "444      0      2      1    1     0   0   0    3    0    0  ...      0    0   \n",
       "477      1      0      0    0     1   0   0    1    0    0  ...      0    0   \n",
       "958      1      0      0    1     0   0   0    0    0    1  ...      0    0   \n",
       "884      0      0      0    0     0   0   0    3    0    2  ...      0    0   \n",
       "678      0      0      0    0     0   0   0    1    0    0  ...      0    0   \n",
       "607      1      1      0    0     0   0   0    1    0    0  ...      1    0   \n",
       "\n",
       "     why  wikipedia  will  with  would  wp  you  your  \n",
       "585    0          0     0     0      0   0    1     0  \n",
       "203    1          0     0     1      0   1    3     0  \n",
       "573    0          0     0     0      0   0    2     0  \n",
       "394    0          0     0     1      0   0    0     0  \n",
       "444    0          0     2     0      0   0    0     0  \n",
       "477    0          1     0     0      0   0    1     0  \n",
       "958    0          0     1     2      0   0    7     2  \n",
       "884    0          0     0     0      0   0    2     0  \n",
       "678    0          0     0     0      0   0    1     1  \n",
       "607    1          1     0     0      1   0    1     0  \n",
       "\n",
       "[10 rows x 150 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the Count Vectorizer to grab the info and Features I would need. \n",
    "vec_cv = CountVectorizer(max_features=150)\n",
    "tmp = vec_cv.fit_transform(train_df[\"comment_text\"])\n",
    "tok_cols = vec_cv.get_feature_names_out()\n",
    "tok_df = pd.DataFrame(tmp.toarray(), columns=tok_cols)\n",
    "print(\"original:\", train_df[\"comment_text\"].shape)\n",
    "print(\"vectorized:\", tmp.shape)\n",
    "tok_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: (1000,)\n",
      "vectorized: (1000, 150)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>after</th>\n",
       "      <th>again</th>\n",
       "      <th>all</th>\n",
       "      <th>also</th>\n",
       "      <th>am</th>\n",
       "      <th>an</th>\n",
       "      <th>and</th>\n",
       "      <th>any</th>\n",
       "      <th>are</th>\n",
       "      <th>...</th>\n",
       "      <th>which</th>\n",
       "      <th>who</th>\n",
       "      <th>why</th>\n",
       "      <th>wikipedia</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>would</th>\n",
       "      <th>wp</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.213828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.256488</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.243484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.104860</td>\n",
       "      <td>0.129561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.271842</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.773396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>0.054425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053974</td>\n",
       "      <td>0.233409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034981</td>\n",
       "      <td>0.05166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.559407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.201923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.269519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.421431</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        about  after  again       all      also        am        an       and  \\\n",
       "146  0.000000    0.0    0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "110  0.000000    0.0    0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "414  0.000000    0.0    0.0  0.213828  0.000000  0.000000  0.000000  0.122244   \n",
       "55   0.000000    0.0    0.0  0.000000  0.000000  0.000000  0.000000  0.190193   \n",
       "693  0.000000    0.0    0.0  0.000000  0.243484  0.000000  0.104860  0.129561   \n",
       "194  0.000000    0.0    0.0  0.000000  0.000000  0.000000  0.000000  0.773396   \n",
       "893  0.054425    0.0    0.0  0.116651  0.000000  0.000000  0.053974  0.233409   \n",
       "701  0.000000    0.0    0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "972  0.000000    0.0    0.0  0.000000  0.000000  0.269519  0.000000  0.267809   \n",
       "226  0.000000    0.0    0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "     any       are  ...  which       who  why  wikipedia      will      with  \\\n",
       "146  0.0  0.000000  ...    0.0  0.000000  0.0   0.000000  0.000000  0.000000   \n",
       "110  0.0  0.000000  ...    0.0  0.000000  0.0   0.000000  0.000000  0.000000   \n",
       "414  0.0  0.166762  ...    0.0  0.000000  0.0   0.197874  0.000000  0.171152   \n",
       "55   0.0  0.000000  ...    0.0  0.000000  0.0   0.000000  0.000000  0.000000   \n",
       "693  0.0  0.088372  ...    0.0  0.000000  0.0   0.000000  0.112248  0.000000   \n",
       "194  0.0  0.000000  ...    0.0  0.000000  0.0   0.000000  0.000000  0.000000   \n",
       "893  0.0  0.000000  ...    0.0  0.000000  0.0   0.000000  0.000000  0.000000   \n",
       "701  0.0  0.000000  ...    0.0  0.559407  0.0   0.000000  0.000000  0.201923   \n",
       "972  0.0  0.182669  ...    0.0  0.000000  0.0   0.000000  0.000000  0.000000   \n",
       "226  0.0  0.000000  ...    0.0  0.000000  0.0   0.000000  0.000000  0.000000   \n",
       "\n",
       "        would   wp       you     your  \n",
       "146  0.000000  0.0  0.000000  0.00000  \n",
       "110  0.000000  0.0  0.000000  0.00000  \n",
       "414  0.000000  0.0  0.256488  0.00000  \n",
       "55   0.000000  0.0  0.000000  0.00000  \n",
       "693  0.114133  0.0  0.271842  0.00000  \n",
       "194  0.000000  0.0  0.000000  0.00000  \n",
       "893  0.000000  0.0  0.034981  0.05166  \n",
       "701  0.000000  0.0  0.000000  0.00000  \n",
       "972  0.000000  0.0  0.421431  0.00000  \n",
       "226  0.000000  0.0  0.000000  0.00000  \n",
       "\n",
       "[10 rows x 150 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TF-IDF\n",
    "vec_tf = TfidfVectorizer(max_features=150, strip_accents=\"unicode\")\n",
    "tmp = vec_tf.fit_transform(train_df[\"comment_text\"])\n",
    "tok_cols = vec_tf.get_feature_names_out()\n",
    "tok_df = pd.DataFrame(tmp.toarray(), columns=tok_cols)\n",
    "print(\"original:\", train_df[\"comment_text\"].shape)\n",
    "print(\"vectorized:\", tmp.shape)\n",
    "tok_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm comparing count vectorization and TF-IDF. Most likely going to use some sort of vectorization parameters. Most likely would be making a tokenizaer to figure out whether it is a threat or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       243\n",
      "           1       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.97       250\n",
      "   macro avg       0.49      0.50      0.49       250\n",
      "weighted avg       0.94      0.97      0.96       250\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Stan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Stan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Stan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model_svc = SVC()\n",
    "\n",
    "vec_cv = CountVectorizer(max_features=150, ngram_range=[1,2])\n",
    "\n",
    "y = train_df[\"obscene\"]\n",
    "X = train_df[\"comment_text\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "pipe1 = Pipeline([ \n",
    "                    (\"vect\", vec_cv),\n",
    "                    (\"model\", model_svc)\n",
    "])\n",
    "\n",
    "params = [\"vec_cv\"]\n",
    "\n",
    "pipe1.fit(X_train, y_train.ravel())\n",
    "preds = pipe1.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds))\n",
    "sns.heatmap(confusion_matrix(y_test, preds), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                       comment_text\n",
       "0   1  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1   2  == From RfC == \\n\\n The title is fine as it is...\n",
       "2   3  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3   4  :If you have a look back at the source, the in...\n",
       "4   5          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>02b8e9f1f138d728</td>\n",
       "      <td>\" Hi, Writingrights, Welcome to Wikipedia!  \\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>02b90e56ec25a4c1</td>\n",
       "      <td>It is common knowledge that Karaims (but not K...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>02b91acc085c26f8</td>\n",
       "      <td>, 12 April 2006 (UTC)\\nThen rewrite and expand...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>02b94ce316048bc1</td>\n",
       "      <td>\"I was trying to inject some humour (as eviden...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>02b9ef57925866c8</td>\n",
       "      <td>this title should redirect to Altona, Hamburg....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                       comment_text  \\\n",
       "0    0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
       "1    000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2    000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3    0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4    0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "..                ...                                                ...   \n",
       "995  02b8e9f1f138d728  \" Hi, Writingrights, Welcome to Wikipedia!  \\n...   \n",
       "996  02b90e56ec25a4c1  It is common knowledge that Karaims (but not K...   \n",
       "997  02b91acc085c26f8  , 12 April 2006 (UTC)\\nThen rewrite and expand...   \n",
       "998  02b94ce316048bc1  \"I was trying to inject some humour (as eviden...   \n",
       "999  02b9ef57925866c8  this title should redirect to Altona, Hamburg....   \n",
       "\n",
       "     toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0        0             0        0       0       0              0  \n",
       "1        0             0        0       0       0              0  \n",
       "2        0             0        0       0       0              0  \n",
       "3        0             0        0       0       0              0  \n",
       "4        0             0        0       0       0              0  \n",
       "..     ...           ...      ...     ...     ...            ...  \n",
       "995      0             0        0       0       0              0  \n",
       "996      0             0        0       0       0              0  \n",
       "997      0             0        0       0       0              0  \n",
       "998      0             0        0       0       0              0  \n",
       "999      0             0        0       0       0              0  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = train_df.copy()\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TextVectorization(max_tokens=150,\n",
    "                               output_sequence_length=1800,\n",
    "                               output_mode='int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can't seem to get the prediction working on the test text_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Exception encountered when calling TextVectorization.call().\n\n\u001b[1m{{function_node __wrapped__LookupTableFindV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Table not initialized. [Op:LookupTableFindV2] name: \u001b[0m\n\nArguments received by TextVectorization.call():\n  • inputs='You freaking suck! I am going to hit you.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# text_column = test_df[\"comment_text\"]\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m text_column \u001b[38;5;241m=\u001b[39m vectorizer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou freaking suck! I am going to hit you.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Make predictions on the text data\u001b[39;00m\n\u001b[0;32m      4\u001b[0m predictions \u001b[38;5;241m=\u001b[39m pipe1\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39marray[text_column])\n",
      "File \u001b[1;32mc:\\Users\\Stan\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Stan\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   5981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m   5982\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 5983\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Exception encountered when calling TextVectorization.call().\n\n\u001b[1m{{function_node __wrapped__LookupTableFindV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Table not initialized. [Op:LookupTableFindV2] name: \u001b[0m\n\nArguments received by TextVectorization.call():\n  • inputs='You freaking suck! I am going to hit you.'"
     ]
    }
   ],
   "source": [
    "# text_column = test_df[\"comment_text\"]\n",
    "text_column = vectorizer('You freaking suck! I am going to hit you.')\n",
    "# Make predictions on the text data\n",
    "predictions = pipe1.predict(np.array[text_column])\n",
    "print(predictions)\n",
    "\n",
    "# test_df[\"predicted_labels\"] = predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>predicted_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153159</th>\n",
       "      <td>153160</td>\n",
       "      <td>. \\n i totally agree, this stuff is nothing bu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153160</th>\n",
       "      <td>153161</td>\n",
       "      <td>== Throw from out field to home plate. == \\n\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153161</th>\n",
       "      <td>153162</td>\n",
       "      <td>\" \\n\\n == Okinotorishima categories == \\n\\n I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153162</th>\n",
       "      <td>153163</td>\n",
       "      <td>\" \\n\\n == \"\"One of the founding nations of the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153163</th>\n",
       "      <td>153164</td>\n",
       "      <td>\" \\n :::Stop already. Your bullshit is not wel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153164 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                       comment_text  \\\n",
       "0            1  Yo bitch Ja Rule is more succesful then you'll...   \n",
       "1            2  == From RfC == \\n\\n The title is fine as it is...   \n",
       "2            3  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
       "3            4  :If you have a look back at the source, the in...   \n",
       "4            5          I don't anonymously edit articles at all.   \n",
       "...        ...                                                ...   \n",
       "153159  153160  . \\n i totally agree, this stuff is nothing bu...   \n",
       "153160  153161  == Throw from out field to home plate. == \\n\\n...   \n",
       "153161  153162  \" \\n\\n == Okinotorishima categories == \\n\\n I ...   \n",
       "153162  153163  \" \\n\\n == \"\"One of the founding nations of the...   \n",
       "153163  153164  \" \\n :::Stop already. Your bullshit is not wel...   \n",
       "\n",
       "        predicted_labels  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "...                  ...  \n",
       "153159                 0  \n",
       "153160                 0  \n",
       "153161                 0  \n",
       "153162                 0  \n",
       "153163                 0  \n",
       "\n",
       "[153164 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    153164.0\n",
       "mean          0.0\n",
       "std           0.0\n",
       "min           0.0\n",
       "25%           0.0\n",
       "50%           0.0\n",
       "75%           0.0\n",
       "max           0.0\n",
       "Name: predicted_labels, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components == 0, must be >= 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\Stan\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 428, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"c:\\Users\\Stan\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Stan\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Stan\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Stan\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Stan\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\fixes.py\", line 117, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Stan\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Stan\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 378, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Stan\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 336, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Stan\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Stan\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 870, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Stan\\anaconda3\\Lib\\site-packages\\sklearn\\decomposition\\_truncated_svd.py\", line 232, in fit_transform\n    check_scalar(\n  File \"c:\\Users\\Stan\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1480, in check_scalar\n    raise ValueError(\nValueError: n_components == 0, must be >= 1.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m results, names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(), \u001b[38;5;28mlist\u001b[39m()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 21\u001b[0m \tscores \u001b[38;5;241m=\u001b[39m evaluate_model(model, tok_df[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1000\u001b[39m], y[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1000\u001b[39m])\n\u001b[0;32m     22\u001b[0m \tresults\u001b[38;5;241m.\u001b[39mappend(scores)\n\u001b[0;32m     23\u001b[0m \tnames\u001b[38;5;241m.\u001b[39mappend(name)\n",
      "Cell \u001b[1;32mIn[11], line 14\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, X, y)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_model\u001b[39m(model, X, y):\n\u001b[0;32m     12\u001b[0m \t\u001b[38;5;66;03m#Splits cut for speed\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \tcv \u001b[38;5;241m=\u001b[39m RepeatedStratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, n_repeats\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m \tscores \u001b[38;5;241m=\u001b[39m cross_val_score(model, X, y, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39mcv, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, error_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "File \u001b[1;32mc:\\Users\\Stan\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Stan\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[0;32m    269\u001b[0m         X,\n\u001b[0;32m    270\u001b[0m         y,\n\u001b[0;32m    271\u001b[0m         scorers,\n\u001b[0;32m    272\u001b[0m         train,\n\u001b[0;32m    273\u001b[0m         test,\n\u001b[0;32m    274\u001b[0m         verbose,\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    276\u001b[0m         fit_params,\n\u001b[0;32m    277\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[0;32m    278\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    279\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[0;32m    280\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Stan\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\Stan\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\Stan\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Stan\\anaconda3\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\Stan\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: n_components == 0, must be >= 1."
     ]
    }
   ],
   "source": [
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tfor i in range(2):\n",
    "\t\tn = i*10\n",
    "\t\tsteps = [('svd', TruncatedSVD(n_components=n)), ('m', LinearSVC(max_iter=100, tol=.01))]\n",
    "\t\tmodels[str(n)] = Pipeline(steps=steps)\n",
    "\treturn models\n",
    " \n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\t#Splits cut for speed\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=2, n_repeats=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\treturn scores\n",
    " \n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model, tok_df[0:1000], y[0:1000])\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "# plot model performance for comparison\n",
    "\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(sublinear_tf=True, ngram_range=(1,3), stop_words=\"english\", strip_accents=\"unicode\")\n",
    "tmp_vec = tf_idf.fit_transform(train_df[\"comment_text\"])\n",
    "\n",
    "tok_cols2 = tf_idf.get_feature_names()\n",
    "tmp_df = pd.DataFrame(tmp_vec.toarray(), columns=tok_cols2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(tmp_df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_tmp = TruncatedSVD(n_components=10)\n",
    "pipe_steps = [(\"scale\", StandardScaler()), (\"svd\", svd_tmp), (\"model\", SVC())]\n",
    "pipe_test = Pipeline(steps=pipe_steps)\n",
    "\n",
    "pipe_test.fit(X_tr, y_tr)\n",
    "pipe_test.score(X_te, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, component in enumerate(svd_tmp.components_):\n",
    "    zipped = zip(tok_cols2, component)\n",
    "    top_terms_key = sorted(zipped, key = lambda t: t[1], reverse=True)[:6]\n",
    "    top_terms_list = list(dict(top_terms_key).keys())\n",
    "    print(\"Topic:\"+str(index)+\" \", top_terms_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
